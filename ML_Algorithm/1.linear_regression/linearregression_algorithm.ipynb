{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thuật toán Linear Regression (Hồi quy tuyến tính).\n",
    "Nội dung:\n",
    "\n",
    "1. Cài đặt thuật toán.\n",
    "2. Sử dụng thư viện scikit-learn.\n",
    "3. Tối ưu hàm mất mát sử dụng thuật toán gradient descent.\n",
    "4. Mở rộng thuật toán hồi quy tuyến tính. (cập nhật)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Cài đặt thuật toán.\n",
    " Linear regression là thuật toán supervised, quan hệ đầu vào giữa đầu ra được mô tả bởi một hàm tuyến tính."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # thư viện hiển thị dữ liệu\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_data(X):\n",
    "    N,d = X.shape\n",
    "    one = np.ones((N,1))\n",
    "    X_bar = np.concatenate((one,X),axis = 1)\n",
    "    return X_bar\n",
    "def linear_regression(X_train,y_train):\n",
    "    X_bar = linear_data(X_train)\n",
    "    A = np.dot(X_bar.T, X_bar)\n",
    "    b = np.dot(X_bar.T, y_train)\n",
    "    w = np.dot(np.linalg.pinv(A), b)\n",
    "    return w\n",
    "def linearregression_predic(X_train,y_train,X_test):\n",
    "    X1 = linear_data(X_test)\n",
    "    w = linear_regression(X_train,y_train)\n",
    "    return X1.dot(w)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ 1. Bài toán về chiều cao và cân nặng.\n",
    "\n",
    "\n",
    "X_train, y_train: lần lượt là chiều cao và cân nặng tương ứng, X_test là chiều cao mới chưa biết cân nặng, y_pred: là cân nặng dự đoán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-33.73541021   0.55920496]\n",
      "[55.7373837  51.26374401]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = np.array([[147, 150, 153, 158, 163, 165, 168, 170, 173, 175, 178, 180, 183]]).T\n",
    "y_train = np.array([ 49, 50, 51,  54, 58, 59, 60, 62, 63, 64, 66, 67, 68])\n",
    "X_test = np.array([[160,152]]).T\n",
    "y_pred = linearregression_predic(X_train,y_train,X_test)\n",
    "print(linear_regression(X_train,y_train))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 Sử dụng thư viện scikit-learn.\n",
    "\n",
    "\n",
    "srouce: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[163]\n",
      " [147]\n",
      " [187]\n",
      " [185]\n",
      " [178]\n",
      " [165]\n",
      " [173]\n",
      " [158]\n",
      " [175]\n",
      " [153]\n",
      " [170]\n",
      " [168]\n",
      " [180]]\n",
      "[58 49 72 71 66 59 63 54 64 51 62 60 67]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split # chia dữ liệu thành hai phần test và set\n",
    "#dữ liệu\n",
    "X = np.array([[147, 150, 153, 158, 163, 165, 168, 170, 173, 175, 178, 180, 183, 185, 187]]).T\n",
    "y = np.array([ 49, 50, 51,  54, 58, 59, 60, 62, 63, 64, 66, 67, 68, 71, 72])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 2 ) # lấy 2 điểm dữ liệu dể dự đoán\n",
    "print(X_train)\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tham số của mô hình: \n",
      "0.5854614300810146 -37.93738992603031\n",
      "Dữ liệu dự đoán: [[150]\n",
      " [183]]\n",
      "Giá trị dự đoán [49.88182459 69.20205178]\n",
      "Gía trị thực: [50 68]\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression() # khởi tạo mô hình\n",
    "regr.fit(X_train,y_train)           # luyện mô hình\n",
    "\n",
    "\n",
    "print(\"Tham số của mô hình: \")\n",
    "print(regr.coef_[0], regr.intercept_)\n",
    "print(\"Dữ liệu dự đoán:\",X_test)\n",
    "y_pred = regr.predict(X_test)\n",
    "print(\"Giá trị dự đoán\",y_pred)\n",
    "print(\"Gía trị thực:\",y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Tối ưu hàm mất mát bằng thuật toán gradient descent.\n",
    "Tìm tham số w thông qua thuật toán gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thuật toán linear regression tìm tham số w bằng cách đạo hàm của hàm mất mát và cho bằng 0. Việc giải phương trình đạo hàm bằng 0 gây khó khăn khi điểm dữ liệu có số chiều lớn, thuật toán gradient descent (GD) đơn giản giúp tìm tham số w gần với nghiệm của bài toán cần tìm (khi đạo hàm xấp xỉ 0). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VD2. Khởi tạo 500 điểm dữ liệu được chọn gần với đường thẳng y = 1 + 2x. Đưa ra tham số của mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tham số w giải bằng sklearn [1.09926074 2.0018674 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "X = np.random.rand(500) # random ra 500 điểm\n",
    "y = 1 + 2*X + .2* np.random.rand(500)\n",
    "#print(X)\n",
    "#print(y)\n",
    "model = LinearRegression()\n",
    "X = X.reshape(-1,1) # reshape về ma trận X gồm N hàng 1 cột\n",
    "y = y.reshape(-1,1)\n",
    "model.fit(X,y)\n",
    "w, b = model.coef_[0][0], model.intercept_[0]\n",
    "sol_sklearn = np.array([b,w])\n",
    "print(\"Tham số w giải bằng sklearn\",sol_sklearn)\n",
    "# print(linear_regression(X,y)): test kết quả với phần 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sử dụng GD để tìm tham số w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = np.ones((X.shape[0],1))\n",
    "X_bar =np.concatenate((one,X),axis = 1)\n",
    "# đạo hàm hàm mất mát\n",
    "def grad(w):\n",
    "    N = X_bar.shape[0]\n",
    "    return 1/N*X_bar.T.dot(X_bar.dot(w)-y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# giá trị hàm mất mát\n",
    "def cost(w):\n",
    "    N = X_bar.shape[0]\n",
    "    return 0.5/N* np.linalg.norm(y-X_bar.dot(w))**2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thuật toán gradient tìm w\n",
    "def lr_gd(w_init, grad, eta):\n",
    "    w = [w_init]\n",
    "    cost_hist =[] # lưu giá trị hàm mất mát sau mỗi vòng lặp\n",
    "    for it in range(100):\n",
    "        w_new = w[-1]- eta*grad(w[-1])\n",
    "        if np.linalg.norm(grad(w_new))/len(w_new) <1e-3:\n",
    "            break\n",
    "        cost_hist.append(cost(w_new))\n",
    "        w.append(w_new)\n",
    "    return (w, it,cost_hist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả tham số:\n",
      " [[1.08443692]\n",
      " [2.0292238 ]]\n",
      "\n",
      "Số vòng lặp 58\n",
      "Hàm mất mát:\n",
      " [0.13297544766505878, 0.08746133697975607, 0.07412299541859518, 0.06449329201412769, 0.056269032101059845, 0.0491302812580024, 0.04292500465677666, 0.03753048212410622, 0.03284073481112168, 0.028763682641915672, 0.025219279376656925, 0.022137936761934675, 0.019459157964983733, 0.017130349799001757, 0.015105790145124861, 0.013345730277600613, 0.011815614466324084, 0.01048540153486755, 0.009328975053960848, 0.008323630590591423, 0.00744962994574705, 0.006689813629030863, 0.006029263961758063, 0.005455012194146739, 0.004955783886355393, 0.004521777554364614, 0.004144472234797653, 0.0038164601905481374, 0.0035313014726794613, 0.0032833974831703145, 0.003067881056129655, 0.0028805208994160123, 0.002717638520537588, 0.002576036005817, 0.0024529332348895206, 0.0023459132978500795, 0.0022528750434092225, 0.0021719918264231012, 0.002101675644876694, 0.002040545962211931, 0.001987402602881067, 0.0019412021889764627, 0.0019010376553106878, 0.0018661204407610518, 0.001835765006236379, 0.001809375375303138, 0.001786433433219373, 0.0017664887546482168, 0.0017491497603357785, 0.0017340760291300248, 0.001720971614400486, 0.001709579233638234, 0.001699675217158997, 0.0016910651167359137, 0.001683579887945048, 0.0016770725712706236, 0.0016714154068092092, 0.0016664973259250756]\n"
     ]
    }
   ],
   "source": [
    "w_init = np.array([[1],[4]])\n",
    "(w1, it1, cost_hit) =lr_gd(w_init, grad, 1)\n",
    "\n",
    "print(\"Kết quả tham số:\\n\",w1[-1])\n",
    "print(\"\\nSố vòng lặp\",it1)\n",
    "print(\"Hàm mất mát:\\n\",cost_hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 Kết luận, mở rộng\n",
    "\n",
    "Thuật toán linear regression nhạy cảm với tín hiệu nhiễu (overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
